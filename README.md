# LangGraph Voice-Enabled Agent Framework

A comprehensive voice-enabled multi-agent framework built on LangGraph with LiveKit integration and extensive MCP (Model Context Protocol) tool adapters.

## ğŸ¯ Overview

This framework provides a complete solution for building sophisticated voice-enabled AI agents that can handle complex development workflows through natural speech interaction. The system combines LangGraph's powerful graph-based agent orchestration with real-time voice communication via LiveKit.

## ğŸ—ï¸ Architecture

### Core Components

- **Voice Integration**: LiveKit WebRTC for real-time audio processing
- **Agent Framework**: LangGraph StateGraph for workflow orchestration
- **MCP Tools**: Comprehensive tool adapters for development workflows
- **Multi-Modal Support**: Seamless text and voice interaction modes

### Agent Ecosystem

1. **Task Orchestrator Agent** (`agents/task_orchestrator.py`)
   - Strategic planning and task delegation
   - Complexity assessment and resource allocation
   - Cross-agent coordination and monitoring

2. **Task Executor Agent** (`agents/task_executor.py`)
   - Implementation and development execution
   - Comprehensive testing and validation
   - Code optimization and documentation

3. **Task Checker Agent** (`agents/task_checker.py`)
   - Quality assurance and validation
   - Multi-level testing strategies
   - Performance and security assessment

## ğŸ› ï¸ MCP Tool Adapters

### Mandatory Tool Order
All agents follow the systematic MCP tool order:
1. **Sequential Thinking** â†’ Problem decomposition and analysis
2. **Serena** â†’ Code intelligence and project navigation
3. **Context7** â†’ Best practices research and documentation

### Available Tools

- **Sequential Thinking** (`tools/sequential_thinking_tools.py`) - Systematic problem analysis
- **Serena** (`tools/serena_tools.py`) - Code intelligence and navigation
- **Context7** (`tools/context7_tools.py`) - Documentation and best practices
- **Taskmaster AI** (`tools/taskmaster_tools.py`) - Task management and research
- **Shrimp Task Manager** (`tools/shrimp_tools.py`) - Advanced task planning
- **Desktop Commander** (`tools/desktop_commander_tools.py`) - File system operations

## ğŸ™ï¸ Voice Features

### Voice Commands
- **Strategic Commands**: "orchestrate project", "analyze complexity", "delegate tasks"
- **Implementation Commands**: "implement feature", "run tests", "optimize code"
- **Quality Commands**: "run validation", "security scan", "quality report"

### Voice Processing
- **Speech-to-Text**: OpenAI Whisper integration
- **Text-to-Speech**: OpenAI TTS with customizable voices
- **Real-time Audio**: LiveKit WebRTC communication
- **Voice Activity Detection**: Automatic speech detection and processing

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Basic Usage
```python
from agents.task_orchestrator import TaskOrchestratorAgent
from voice.livekit_client import create_livekit_client

# Create voice-enabled orchestrator
livekit_client = await create_livekit_client(
    agent_type="orchestrator",
    session_id="demo-session",
    participant_name="AI-Agent",
    livekit_url="wss://your-livekit-server.com",
    api_key="your-api-key",
    api_secret="your-api-secret",
    openai_api_key="your-openai-key"
)

agent = TaskOrchestratorAgent(
    session_id="demo-session",
    livekit_client=livekit_client
)

# Run via voice or text
result = await agent.run({
    "messages": [],
    "task_description": "Build a REST API with authentication"
})
```

## ğŸ“ Project Structure

```
langgraph-flows/
â”œâ”€â”€ agents/                 # Core agent implementations
â”‚   â”œâ”€â”€ task_orchestrator.py   # Strategic planning agent
â”‚   â”œâ”€â”€ task_executor.py       # Implementation agent
â”‚   â””â”€â”€ task_checker.py        # Quality assurance agent
â”œâ”€â”€ core/                   # Framework foundation
â”‚   â”œâ”€â”€ base_agent.py          # Base agent class
â”‚   â”œâ”€â”€ base_graph.py          # Graph utilities
â”‚   â”œâ”€â”€ multimodal_mixin.py    # Voice/text support
â”‚   â””â”€â”€ state_management.py    # State persistence
â”œâ”€â”€ tools/                  # MCP tool adapters
â”‚   â”œâ”€â”€ sequential_thinking_tools.py
â”‚   â”œâ”€â”€ serena_tools.py
â”‚   â”œâ”€â”€ context7_tools.py
â”‚   â”œâ”€â”€ taskmaster_tools.py
â”‚   â”œâ”€â”€ shrimp_tools.py
â”‚   â””â”€â”€ desktop_commander_tools.py
â”œâ”€â”€ voice/                  # Voice integration
â”‚   â””â”€â”€ livekit_client.py      # LiveKit WebRTC client
â”œâ”€â”€ examples/               # Usage examples
â”œâ”€â”€ tests/                  # Test suites
â””â”€â”€ patterns/               # Common workflows
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# OpenAI API (for voice processing)
OPENAI_API_KEY=your_openai_api_key

# LiveKit (for voice communication)
LIVEKIT_URL=wss://your-livekit-server.com
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret

# MCP Tool Configuration
TASKMASTER_API_KEY=your_taskmaster_key
SERENA_PROJECT_PATH=/path/to/your/project
CONTEXT7_API_KEY=your_context7_key
```

### Agent Configuration
```python
# Customize agent behavior
agent_config = {
    "validation_level": "comprehensive",
    "voice_enabled": True,
    "auto_delegation": True,
    "quality_threshold": 85.0
}
```

## ğŸ§ª Testing

Run the comprehensive test suite:
```bash
# Unit tests
pytest tests/unit/

# Integration tests
pytest tests/integration/

# Voice interaction tests
pytest tests/voice/

# Full test suite
pytest tests/ -v --cov=.
```

## ğŸ“š Documentation

- **Agent Development Guide**: `docs/agent_development.md`
- **Voice Integration Guide**: `docs/voice_integration.md`
- **MCP Tool Reference**: `docs/mcp_tools.md`
- **API Documentation**: `docs/api_reference.md`

## ğŸ¯ Key Features

### Multi-Modal Interaction
- **Voice-First Design**: Natural speech interaction for all workflows
- **Text Fallback**: Full text-based operation when voice unavailable
- **Context Switching**: Seamless mode transitions during operation

### Advanced Orchestration
- **Dependency Management**: Automatic task dependency resolution
- **Resource Allocation**: Intelligent agent and tool selection
- **Progress Monitoring**: Real-time workflow tracking and reporting

### Quality Assurance
- **Multi-Level Validation**: Basic to enterprise-grade quality checks
- **Automated Testing**: Comprehensive test execution and reporting
- **Performance Monitoring**: Real-time metrics and optimization

### State Management
- **Persistent State**: SQLite/Redis hybrid storage
- **Session Recovery**: Automatic state restoration
- **Cross-Agent Sync**: Shared state across agent instances

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ† Acknowledgments

- **LangGraph**: Graph-based agent framework foundation
- **LiveKit**: Real-time voice communication infrastructure
- **MCP Protocol**: Model Context Protocol for tool integration
- **OpenAI**: Speech processing and AI capabilities

## ğŸ”— Links

- [GitHub Repository](https://github.com/ScientiaCapital/langgraph-voice-agents)
- [Documentation](https://github.com/ScientiaCapital/langgraph-voice-agents/docs)
- [Issues](https://github.com/ScientiaCapital/langgraph-voice-agents/issues)
- [Discussions](https://github.com/ScientiaCapital/langgraph-voice-agents/discussions)

---

Built with â¤ï¸ for the future of voice-enabled AI development.